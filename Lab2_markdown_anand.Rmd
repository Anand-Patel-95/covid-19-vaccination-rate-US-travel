---
title: "Lab2_markdown_anand"
author: "Anand Patel"
date: "7/26/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(magrittr)
library(ggplot2)
library(patchwork)
library(sandwich)
library(lmtest)
library(stargazer)
library(car)
library(GGally)


```


Load in the dataset.

```{r message=FALSE, include=FALSE}
# on anand's computer:
setwd("/home/rstudio/w203/lab-2-section8-team5-lab2-avv/src/data")

# column_classes <- c("character", "numeric", "character", "character", "numeric", "integer", "numeric", "integer", "numeric", "integer", "character")

trips.vs.vaccine.df <- read.csv('final_data_v1.csv', header = TRUE, stringsAsFactors = FALSE)

trips.vs.vaccine.df$X <- NULL
trips.vs.vaccine.df$isRepublican = as.factor(trips.vs.vaccine.df$isRepublican)
```



```{r include=FALSE}
get_robust_se <- function(model) { 
    require(sandwich)
    
    sqrt(diag(sandwich::vcovHC(model)))
  }
```



## Exploratory Data Analysis

```{r conduct EDA in this chunk}


# untransformed Number.of.Long.Trips vs Series_Complete_Pop_Pct
d_scatter <- trips.vs.vaccine.df %>% 
  ggplot() + 
  aes(x = (Series_Complete_Pop_Pct), y= (Number.of.Long.Trips)) + 
  geom_smooth(method='lm', se=FALSE, alpha=0.8) +
  geom_point(alpha = 0.1) +
  labs(
    title    = 'Number of Long Trips Taken vs. Vaccination %',
    x        = 'Vaccination %',
    y        = 'Number of Long Trips Taken', 
    fill     = ''
  ) +
  theme_light()

d_scatter


# log transformed on Number.of.Long.Trips.
d_scatter <- trips.vs.vaccine.df %>% 
  ggplot() + 
  aes(x = (Series_Complete_Pop_Pct), y= log10(Number.of.Long.Trips)) + 
  geom_smooth(method='lm', se=FALSE, alpha=0.8) +
  geom_point(alpha = 0.1) +
  labs(
    title    = 'Number of Long Trips Taken vs. Vaccination %',
    x        = 'Vaccination %',
    y        = 'Number of Long Trips Taken log(10)', 
    fill     = ''
  ) +
  theme_light()

d_scatter

```


```{r message=FALSE}

# plot the scatter plot, with interaction terms
# ignore this

trips.vs.vaccine.df %>% 
  select(Number.of.Long.Trips, Series_Complete_Pop_Pct, isRepublican) %>% 
  mutate(isRepublican = factor(isRepublican, levels=c("1", "0"))) %>% 
  ggplot(aes(x=Series_Complete_Pop_Pct, y=log10(Number.of.Long.Trips), color=isRepublican)) +
  geom_point(alpha=0.7) + theme_classic() +
  geom_smooth(method='lm', se=FALSE, alpha=0.8) + 
  scale_color_manual(values=c("red", "blue")) +
  theme(legend.position="bottom") + 
  labs(
    title="Relationship between Vaccination % and Number of Long Trips Taken",
    subtitle="Interaction Terms between isRepublican (red) and % of Vaccinated Population",
    x="% of Vaccinated Population", y="Number of Long Trips Taken", color=NULL 
  )
```


```{r}
# convert county_median_income to per 1000?
```


Correlation Matrix between terms of interest.

```{r}

# Just for our analysis, no need to include in report

install.packages("inspectdf")
library(inspectdf)

# Creating a dataframe with only the required columns
data_unlabeled <- trips.vs.vaccine.df %>% 
  select(Number.of.Long.Trips, 
         Series_Complete_Pop_Pct,
         County.POP,
         County_Median_Income,
         Income_CountyMedian_vs_StateMedian,
         isRepublican,
         unemployment_pct_2020,
         MEDIAN_AGE_TOT
  )

inspect_cor(data_unlabeled) %>% show_plot(col_palette = 5)

```



The correlation matrix shows very high positive correlation between `Income County Median Income vs State Median Income`, representing what percentage of the state's median income the county median income has, and `County Median Income`. We will only use county median income to represent wealth as a control for our analysis. 


```{r}
# 1) untransformed data
pairs(~Number.of.Long.Trips + Series_Complete_Pop_Pct + County.POP + County_Median_Income + isRepublican + unemployment_pct_2020 + MEDIAN_AGE_TOT, data = trips.vs.vaccine.df)

# 2) log10 transformed `Number.of.Long.Trips`
pairs(~log10(Number.of.Long.Trips) + Series_Complete_Pop_Pct + County.POP + County_Median_Income + isRepublican + unemployment_pct_2020 + MEDIAN_AGE_TOT, data = trips.vs.vaccine.df)

# 3) log10 transformed `Number.of.Long.Trips`, log10 transformed `County.POP`
pairs(~log10(Number.of.Long.Trips) + Series_Complete_Pop_Pct + log10(County.POP) + log10(County_Median_Income) + isRepublican + log10(unemployment_pct_2020) + MEDIAN_AGE_TOT, data = trips.vs.vaccine.df)
```

### GGPair plots to transform our variables to be more normal.

First we create a dataframe with our predictors and outcome variable untransformed. We use a GGPairs to look at the correlation between variables, the distributions of the variables along the plot diagonal, and scatterplots of each variable pair.

```{r message=FALSE, warning=FALSE, include=FALSE}

# create df for just the outcome variable and predictors.
d <- trips.vs.vaccine.df[, c(2, 5, 7, 8, 11, 12, 16)]

```



```{r message=FALSE, warning=FALSE}
# Plot untransformed ggpairs

pm <- ggpairs(d, 1:7,
    title = "Untransformed: GGPairs plots for Outcome and Features"
)
pm

```


In the plot above, we see that several variables have non-normal distributions. The following variable's distributions look right skewed: `Number.of.Long.Trips`, `Series_Complete_Pop_Pct` (slightly), `County.POP`, `County_Median_Income`, `unemployment_pct_2020`, `unemployment_pct_2020` (slightly). For right-skewed distributions, we can transform our variables down the Box-Cox Ladder of Powers. We try transforming our right-skewed variables using a log10 transform, and plotting the GGPairs again to see if we have more normally distributed variables now.

```{r include=FALSE}
# create transformed dataframe
d_tf <- d

# log10
d_tf$Number.of.Long.Trips = log10(d_tf$Number.of.Long.Trips)

# log10
d_tf$Series_Complete_Pop_Pct = log10(d_tf$Series_Complete_Pop_Pct)

# log10
d_tf$County.POP = log10(d_tf$County.POP)

# log10
d_tf$County_Median_Income = log10(d_tf$County_Median_Income)

# log10
d_tf$unemployment_pct_2020 = log10(d_tf$unemployment_pct_2020)

# log10
d_tf$MEDIAN_AGE_TOT = log10(d_tf$MEDIAN_AGE_TOT)


```



```{r message=FALSE, warning=FALSE}
# Plot untransformed ggpairs

pm2 <- ggpairs(d_tf, 1:7,
    title = "Untransformed: GGPairs plots for Outcome and Features"
)
pm2

```


All of the variables' distributions look much more normal now. The `County_Median_Income` still looks a bit right-skewed. We could go one step further down on the box-cox ladder of powers to transform this feature using a reciprocal root, but that comes at the cost of interpreting the coefficient for `County_Median_Income`. We will choose to log base 10 transform all the variables.

## Create models

$$\log_{10}{\text{Long_Distance_Trips }} =   \beta_0 +  \beta_1    \text{Fully_Vaccinated_Pct}$$



```{r}

model_limited = lm(formula = log10(Number.of.Long.Trips) ~ Series_Complete_Pop_Pct, data = trips.vs.vaccine.df)

model_2 = lm(formula = log10(Number.of.Long.Trips) ~ Series_Complete_Pop_Pct + log10(County.POP) + log10(County_Median_Income), data = trips.vs.vaccine.df)

model_3 = lm(formula = log10(Number.of.Long.Trips) ~ Series_Complete_Pop_Pct + log10(County.POP) + log10(County_Median_Income) + isRepublican + log10(unemployment_pct_2020) + MEDIAN_AGE_TOT, data = trips.vs.vaccine.df)

```


Using our log10 transformed data, we create a limited model, a second model with selective controls, and a third model with all our covariates.

```{r include=FALSE}
d_log10 = d_tf

d_log10 = rename(d_log10, Number.of.Long.Trips_log10 = Number.of.Long.Trips, Series.Complete.Pop.Pct_log10 = Series_Complete_Pop_Pct, County.POP_log10 = County.POP, County.Median.Income_log10 = County_Median_Income, Unemployment.Pct_log10 = unemployment_pct_2020, Median.Age_log10 = MEDIAN_AGE_TOT)

```



### Make Models

```{r}

model_limited = lm(formula = Number.of.Long.Trips_log10 ~ Series.Complete.Pop.Pct_log10, data = d_log10)

model_2 = lm(formula = Number.of.Long.Trips_log10 ~ Series.Complete.Pop.Pct_log10 + County.POP_log10 + County.Median.Income_log10, data = d_log10)

model_3 = lm(formula = Number.of.Long.Trips_log10 ~ Series.Complete.Pop.Pct_log10 + County.POP_log10 + County.Median.Income_log10 + isRepublican + Unemployment.Pct_log10 + Median.Age_log10, data = d_log10)

```


#### Run Akaike information criterion (AIC)

Run the Akaike Information Criterion (AIC) to see which models fit the given data the most.

```{r}
step(model_limited, list(upper = model_3), direction = "forward")
```


The AIC tests show that the model with the lowest AIC score, which fits the model the best, is actually the model that only excludes the unemployment percentage variable. We can update our 2nd model to this model.

```{r}

model_limited = lm(formula = Number.of.Long.Trips_log10 ~ Series.Complete.Pop.Pct_log10, data = d_log10)

model_2 = lm(formula = Number.of.Long.Trips_log10 ~ Series.Complete.Pop.Pct_log10 + County.POP_log10 + Median.Age_log10 + isRepublican + County.Median.Income_log10, data = d_log10)

model_3 = lm(formula = Number.of.Long.Trips_log10 ~ Series.Complete.Pop.Pct_log10 + County.POP_log10 + County.Median.Income_log10 + isRepublican + Unemployment.Pct_log10 + Median.Age_log10, data = d_log10)

```




```{r}
# add residuals 
d_log10 <- d_log10 %>%  
  mutate(model_limited_residuals = resid(model_limited)) # model predict - actual

d_log10 <- d_log10 %>% 
  mutate(model_limited_prediction = predict(model_limited))

d_log10 <- d_log10 %>%  
  mutate(model_2_residuals = resid(model_2)) # model predict - actual

d_log10 <- d_log10 %>% 
  mutate(model_2_prediction = predict(model_2))

d_log10 <- d_log10 %>%  
  mutate(model_3_residuals = resid(model_3)) # model predict - actual

d_log10 <- d_log10 %>% 
  mutate(model_3_prediction = predict(model_3))
```



```{r eval=FALSE, include=FALSE}
# add residuals 
trips.vs.vaccine.df <- trips.vs.vaccine.df %>%  
  mutate(model_limited_residuals = resid(model_limited)) # model predict - actual

trips.vs.vaccine.df <- trips.vs.vaccine.df %>% 
  mutate(model_limited_prediction = predict(model_limited))

trips.vs.vaccine.df <- trips.vs.vaccine.df %>%  
  mutate(model_2_residuals = resid(model_2)) # model predict - actual

trips.vs.vaccine.df <- trips.vs.vaccine.df %>% 
  mutate(model_2_prediction = predict(model_2))

trips.vs.vaccine.df <- trips.vs.vaccine.df %>%  
  mutate(model_3_residuals = resid(model_3)) # model predict - actual

trips.vs.vaccine.df <- trips.vs.vaccine.df %>% 
  mutate(model_3_prediction = predict(model_3))
```


#### Plotting models



```{r}
plot(model_limited)
```


```{r}
bptest(model_limited)

```



```{r}
plot(model_2)
```


```{r}
bptest(model_2)

```


```{r}
plot(model_3)
```


```{r}
bptest(model_3)
```


Using Robust Standard Errors

```{r message=FALSE, warning=FALSE}
stargazer(
   model_limited, model_2, model_3,
   type = 'text',
   se = list(get_robust_se(model_limited), get_robust_se(model_2), get_robust_se(model_3)) # use robust standard errors
   )
```


-----------

## 1. An Introduction
Your introduction should present a research question and explain the concept that you’re attempting to measure and how it will be operationalized. This section should pave the way for the body of the report, preparing the reader to understand why the models are constructed the way that they are. It is not enough to simply say “We are looking for policies that help against COVID” Your introduction must do work for you, focusing the reader on a specific measurement goal, making them care about it, and propelling the narrative forward. This is also good time to put your work into context, discuss cross-cutting issues, and assess the overall appropriateness of the data.

### Research Question

### Operationalization 

## 2. A Model Building Process
You will next build a set of models to investigate your research question, documenting your decisions. Here are some things to keep in mind during your model building process:

What do you want to measure? Make sure you identify one, or a few, variables that will allow you to derive conclusions relevant to your research question, and include those variables in all model specifications. How are the variables that you will be modeling distributed? Provide enough context and information about your data for your audience to understand whatever model results you will eventually present.

### Variables of Interest

Is your modeling goal one of description or **explanation**?

What covariates help you achieve your modeling goals? What covariates are problematic, either due to collinearity, or because they will absorb some of a causal effect you want to measure?

#### Potential Covariates

What transformations, if any, should you apply to each variable? These transformations might reveal linearities in the data, make our results relevant, or help us meet model assumptions.

#### Transformations

Are your choices supported by exploratory data analysis (EDA)? You will likely start with some general EDA to detect anomalies (missing values, top-coded variables, etc.). From then on, your EDA should be interspersed with your model building. Use visual tools to guide your decisions. You can also leverage statistical tests to help assess whether variables, or groups of variables, are improving model fit.

At the same time, it is important to remember that you are not trying to create one perfect model. You will create several specifications, giving the reader a sense of how robust (or sensitive) your results are to modeling choices, and to show that you’re not just cherry-picking the specification that leads to the largest effects.

At a minimum, you should include the following three specifications:

Limited Model: The first model you include should include only the key variables you want to measure. These variables might be transformed, as determined by your EDA, but the model should include the absolute minimum number of covariates (perhaps one, or at most two-three, covariates if they are so crucial that it would be unreasonable to omit them).

Model Two: One model that includes key explanatory variables and covariates that you believe advance your modeling goals without introducing too much multicollinearity or causing other issues of confounding. This model should strike a balance between accuracy and parsimony and reflect your best understanding of the relationships among key variables.

Model Three: One model that includes the previous covariates, and many other covariates, erring on the side of inclusion. A key purpose of this model is to evaluate how parameters of interest change (if at all) when additional, potentially colinear variables are included in the model specification.
You goal with producing these models is to choose models that encircle the space of reasonable modeling choices, and to give an overall understanding of how these choices impact results.

### Models

## 3. A Regression Table
You should display all of your model specifications in a regression table, using a package like stargazer to format your output. It should be easy for the reader to find the coefficients that represent key effects near the top of the regression table, and scan horizontally to see how they change from specification to specification. Make sure that you display the most appropriate standard errors in your table.

In your text, comment on both statistical significance and practical significance. You may want to include statistical tests besides the standard t-tests for regression coefficients.

### f-tests to determine the benefit of added covariates


```{r f-test}

anova(model_2, model_3, data = d_log10, test = "F")


# anova(model_2, lm(formula = log10(Number.of.Long.Trips) ~ Series_Complete_Pop_Pct + log10(County.POP) + log10(County_Median_Income) + log10(unemployment_pct_2020), data = trips.vs.vaccine.df), test = "F")



# anova(model_2, model_3, test = "F")

```



### Statistical Significance

### Practical Significance

## 4. Limitations of your Model
As a team, evaluate all of the CLM assumptions that must hold for your model. However, do not report an exhaustive examination all 5 CLM assumptions in the main report. Instead, bring forward only those assumptions that you or your reader might think pose significant problems for your analysis. For each problem that you identify, describe the statistical consequences. If you are able to identify any strategies to mitigate the consequences, explain these strategies.

### CLM Assumption 1: IID

### CLM Assumption 2: Linear Conditional Expectation

```{r}
plot(model_limited,which=1)
```


```{r}
# model 1

plot_model_1a <- d_log10 %>%  
  ggplot(aes(x = Series.Complete.Pop.Pct_log10, y = Number.of.Long.Trips_log10)) + 
  geom_point() + stat_smooth()

plot_model_1b <- d_log10 %>%  
  ggplot(aes(x = Series.Complete.Pop.Pct_log10, y = model_limited_residuals)) + 
  geom_point() + stat_smooth()

(plot_model_1a / plot_model_1b)

```




```{r}
plot(model_2,which=1)
```



```{r message=FALSE}
# model 2

plot_model_2a <- d_log10 %>%  
  ggplot(aes(x = Series.Complete.Pop.Pct_log10, y = model_2_residuals)) + 
  geom_point() + stat_smooth()

plot_model_2b <- d_log10 %>% 
  ggplot(aes(x = County.POP_log10, y = model_2_residuals)) + 
  geom_point() + stat_smooth()

plot_model_2c <- d_log10 %>% 
  ggplot(aes(x = County.Median.Income_log10, y = model_2_residuals)) + 
  geom_point() + stat_smooth()

plot_model_2d <- d_log10 %>%  
  ggplot(aes(x = model_2_prediction, y = model_2_residuals)) + 
  geom_point() + stat_smooth()

(plot_model_2a | plot_model_2b) / (plot_model_2c | plot_model_2d)

```




```{r}
plot(model_3,which=1)
```



```{r message=FALSE, warning=FALSE}
# model 3

plot_model_3a <- d_log10 %>%  
  ggplot(aes(x = Series.Complete.Pop.Pct_log10, y = model_3_residuals)) + 
  geom_point() + stat_smooth()

plot_model_3b <- d_log10 %>% 
  ggplot(aes(x = County.POP_log10, y = model_3_residuals)) + 
  geom_point() + stat_smooth()

plot_model_3c <- d_log10 %>% 
  ggplot(aes(x = County.Median.Income_log10, y = model_3_residuals)) + 
  geom_point() + stat_smooth()

plot_model_3d <- d_log10 %>% 
  ggplot(aes(x = as.numeric(isRepublican), y = model_3_residuals)) + 
  geom_point() + stat_smooth()

plot_model_3e <- d_log10 %>% 
  ggplot(aes(x = Unemployment.Pct_log10, y = model_3_residuals)) + 
  geom_point() + stat_smooth()

plot_model_3f <- d_log10 %>% 
  ggplot(aes(x = Median.Age_log10, y = model_3_residuals)) + 
  geom_point() + stat_smooth()

plot_model_3g <- d_log10 %>%  
  ggplot(aes(x = model_3_prediction, y = model_3_residuals)) + 
  geom_point() + stat_smooth()

(plot_model_3a | plot_model_3b) / (plot_model_3c | plot_model_3d) / (plot_model_3e | plot_model_3f)

```


### CLM Assumption 3: No Perfect Multicollinearity

Since we did not get NA's or variables dropped in our regression table, 
*perfect* multicollinearity does not exist in our model. We check for near perfect multicollinearity through VIF tests of our model. If a variable's VIF is over 4, then that variable is collinear with atleast another and should be considered for dropping. 


```{r}
car::vif(model_2)

```


```{r}
car::vif(model_3)

```


### CLM Assumption 4: Homoskedastic Conditional Variance


```{r}
plot(model_limited,which=3)
plot(model_2,which=3)
plot(model_3,which=3)


```


```{r}
bptest(model_2)
bptest(model_3)

```

We should use robust standard errors b/c we do not have homoskedasticity.

### CLM Assumption 5: Normally Distributed Errors

```{r}
car::qqPlot(model_limited)
car::qqPlot(model_2)
car::qqPlot(model_3)



```


```{r}
hist(model_limited$residuals)
hist(model_2$residuals)
hist(model_3$residuals)



```



Note that you may need to change your model specifications in response to violations of the CLM.

## 5. Discussion of Omitted Variables
If the team has taken up an explanatory (i.e. causal) question to evaluate, then identify what you think are the most important omitted variables that bias results you care about. For each variable you name, you should reason about the direction of bias caused by omitting this variable. If you can argue whether the bias is large or small, that is even better. State whether you have any variables available that may proxy (even imperfectly) for the omitted variable. Pay particular attention to whether each omitted variable bias is towards zero or away from zero. You will use this information to judge whether the effects you find are likely to be real, or whether they might be entirely an artifact of omitted variable bias.

## 6. Conclusion
Make sure that you end your report with a discussion that distills key insights from your estimates and addresses your research question.